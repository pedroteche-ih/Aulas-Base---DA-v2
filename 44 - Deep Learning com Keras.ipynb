{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedroteche-ih/99_PT_JAN2023/blob/main/aulas/20230530%20Deep%20Learning%20com%20Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rBF3bjoVxOU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import KNNImputer, SimpleImputer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning\n",
        "\n",
        "## Modelos de Classificação"
      ],
      "metadata": {
        "id": "2QntZNF5WBi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/pedroteche-ih/64_PT_NOV202111/main/aulas/data/tb_hotel_completa.csv'\n",
        "tb_hotel = pd.read_csv(url)\n",
        "tb_hotel['is_company'] = np.where(tb_hotel['company'].isna(), 0, 1)\n",
        "tb_hotel['is_agent'] = np.where(tb_hotel['agent'].isna(), 0, 1)"
      ],
      "metadata": {
        "id": "WS5sNYA5WCp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tb_hotel.info()"
      ],
      "metadata": {
        "id": "s7oG7w97kDte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construindo Pipelines"
      ],
      "metadata": {
        "id": "Xcdsg4--W3ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer"
      ],
      "metadata": {
        "id": "epyiPkQcW1ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tb_hotel.select_dtypes(include = \"number\").columns"
      ],
      "metadata": {
        "id": "6c_QUX-gXIYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_vars = [\n",
        "    'hotel', 'meal', 'country', \n",
        "    'market_segment', 'distribution_channel',\n",
        "    'reserved_room_type', 'assigned_room_type', \n",
        "    'deposit_type', 'customer_type', 'is_company', 'is_agent'\n",
        "]\n",
        "num_vars = [\n",
        "    'lead_time', 'stays_in_weekend_nights',\n",
        "    'stays_in_week_nights', 'adults', 'children', 'babies',\n",
        "    'is_repeated_guest', 'previous_cancellations',\n",
        "    'previous_bookings_not_canceled','days_in_waiting_list', \n",
        "    'adr', 'required_car_parking_spaces',\n",
        "    'total_of_special_requests'\n",
        "]"
      ],
      "metadata": {
        "id": "yoyxDRtSW_Zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Braço Numérico"
      ],
      "metadata": {
        "id": "3ZAikAUBX_f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_imputer = KNNImputer(n_neighbors = 5, weights = 'distance')\n",
        "num_scaler = StandardScaler()\n",
        "num_pipeline = Pipeline([('IMPUTER', num_imputer), ('SCALER', num_scaler)])\n"
      ],
      "metadata": {
        "id": "_nfLFYHyXWYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Braço Categórico"
      ],
      "metadata": {
        "id": "-5Wtzp2oYdwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_imputer = SimpleImputer(strategy = 'constant', fill_value = 'Unknown')\n",
        "ohe = OneHotEncoder(\n",
        "    drop = 'first', \n",
        "    handle_unknown = 'ignore',\n",
        "    min_frequency = 10\n",
        ")\n",
        "cat_pipeline = Pipeline([('IMPUTER', cat_imputer), ('OHE', ohe)])"
      ],
      "metadata": {
        "id": "gTqr_03yYaKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pipeline Final"
      ],
      "metadata": {
        "id": "k1-azUowbqPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "composed = ColumnTransformer([('CAT', cat_pipeline, cat_vars),\n",
        "                              ('NUM', num_pipeline, num_vars)])\n",
        "dataprep_pipeline = Pipeline([('DATAPREP', composed)])"
      ],
      "metadata": {
        "id": "0MJt3oNzZm7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tb_hotel[cat_vars + num_vars]\n",
        "y = np.array(tb_hotel['is_canceled'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "metadata": {
        "id": "Y-N5pbs4b9pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataprep_pipeline.fit(X_train)\n",
        "X_train_trans = dataprep_pipeline.transform(X_train)\n",
        "X_test_trans = dataprep_pipeline.transform(X_test)"
      ],
      "metadata": {
        "id": "iXWyrPAxcKtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = X_train_trans.shape[1]\n",
        "print(num_features)"
      ],
      "metadata": {
        "id": "iaU88bCfdGpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando nossa Rede Neural"
      ],
      "metadata": {
        "id": "KfmeCAhocsR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "metadata": {
        "id": "kr0JIH_ycnoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "UXVktARcffhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definindo a topologia\n",
        "\n",
        "Na definição da topologia precisamos prestar atenção à alguns parametros:\n",
        "\n",
        "1. `input_dim` na primeira camada deve ser o número de features em nosso modelo;\n",
        "1. `activation` nas camadas escondidas é hiperparâmetro a ser testado;\n",
        "1. `activation` na última camada é uma função do tipo de modelo que queremos construir:\n",
        "  * \"sigmoid\" para classificação binária;\n",
        "  * \"softmax\" para multi-classificação;\n",
        "  * não precisa ser especificada para problemas de regressão;\n",
        "1. o **tamanho da última camada** deve corresponder ao tipo de previsão que queremos fazer:\n",
        "  * **1** para problemas de classificação binária;\n",
        "  * **n** para problemas de classificação com *n* categorias;\n",
        "  * **1** para problemas de regressão.\n",
        "\n",
        "Além das camadas densas (como as camadas de um MLP) vamos adicionar uma camada de `Dropout`: \n",
        "\n",
        "1. Camadas de *dropout* tem uma probabilidade de não passar as informações de alguns neurônios de uma camada para a próxima - essa técnica ajuda redes profundas a evitar overfitting.\n",
        "1. O único hiperparâmetro de uma cada `Dropout` é *p*, a % de neurônios que são bloqueados em cada batch."
      ],
      "metadata": {
        "id": "2ZGLkqJZeaAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim=num_features, activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(20, activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "jjBP45v9czTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora podemos compilar nosso modelo. O parâmetro fundamental dessa função é a *loss function*, que é consequência do problema que queremos resolver:\n",
        "\n",
        "1. `binary_crossentropy` para problemas de classificação binária;\n",
        "1. `categorical_crossentropy` para problemas de multi-classificação;\n",
        "1. `mean_squared_error` para problemas de regressão.\n",
        "\n",
        "https://keras.io/api/losses/\n",
        "\n",
        "De forma semelhante, a métrica utilizada precisa refletir o tipo de problema que estamos resolvendo:\n",
        "\n",
        "https://keras.io/api/metrics/"
      ],
      "metadata": {
        "id": "qgWNSgPzm5Lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer='adam', \n",
        "    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "pCKicf_VeMV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Estimando pesos\n",
        "\n",
        "O principal hiperparâmetro em um modelo de Deep Learning é o número de *épocas* (`epochs`) - que representa por quantas rodadas de otimização nossa rede passará. Um número maior de épocas melhora nosso modelo mas pode causar overfitting!"
      ],
      "metadata": {
        "id": "syWl7V4Jecy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h = model.fit(X_train_trans.toarray(), y_train, epochs = 25, batch_size = 64, validation_split = 0.1)"
      ],
      "metadata": {
        "id": "pm8YmXqjeV2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model.predict(X_test_trans)\n",
        "y_pred_prob"
      ],
      "metadata": {
        "id": "A7V2EgLSeme_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = [1 if x > 0.5 else 0 for x in y_pred_prob]\n",
        "y_pred[0:10]"
      ],
      "metadata": {
        "id": "orm3EW5zioFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "print(f\"F1-Scoreo no Conjunto de Teste: {np.round(f1_score(y_test, y_pred), 3)}\")"
      ],
      "metadata": {
        "id": "URin8WMFiz1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizando Overfitting\n",
        "\n",
        "Para visualizar overfitting, vamos criar uma rede profunda, com mais camadas:"
      ],
      "metadata": {
        "id": "jf2fTHrrjRaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(Dense(80, input_dim=num_features, activation=\"relu\"))\n",
        "model_2.add(Dropout(0.1))\n",
        "model_2.add(Dense(80, activation=\"relu\"))\n",
        "model_2.add(Dropout(0.1))\n",
        "model_2.add(Dense(80, activation=\"relu\"))\n",
        "model_2.add(Dropout(0.1))\n",
        "model_2.add(Dense(80, activation=\"relu\"))\n",
        "model_2.add(Dropout(0.1))\n",
        "model_2.add(Dense(80, activation=\"relu\"))\n",
        "model_2.add(Dropout(0.1))\n",
        "model_2.add(Dense(80, activation=\"relu\"))\n",
        "model_2.add(Dropout(0.1))\n",
        "model_2.add(Dense(80, activation=\"relu\"))\n",
        "model_2.add(Dropout(0.1))\n",
        "model_2.add(Dense(80, activation=\"relu\"))\n",
        "model_2.add(Dropout(0.1))\n",
        "model_2.add(Dense(80, activation=\"relu\"))\n",
        "model_2.add(Dropout(0.1))\n",
        "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
        "model_2.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer='adam', \n",
        "    metrics=[keras.metrics.Precision(), keras.metrics.Recall()])"
      ],
      "metadata": {
        "id": "ekpdbF6kjWuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_2.fit(\n",
        "    X_train_trans.toarray(), y_train,\n",
        "    validation_split = 0.1, \n",
        "    epochs=25, batch_size=64)"
      ],
      "metadata": {
        "id": "N9ixf4T6jHiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history.keys()"
      ],
      "metadata": {
        "id": "wHuBn4PNkyke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tb_eval = pd.DataFrame({'precision' : history.history['precision'], \n",
        "                        'recall' : history.history['recall'], \n",
        "                        'val_precision' : history.history['val_precision'], \n",
        "                        'val_recall' : history.history['val_recall'], \n",
        "                        'epoch' : range(25)})"
      ],
      "metadata": {
        "id": "vphrGLkijg81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tb_eval['f1_score'] = 2 * (tb_eval['precision'] * tb_eval['recall'])/(tb_eval['precision'] + tb_eval['recall'])\n",
        "tb_eval['val_f1_score'] = 2 * (tb_eval['val_precision'] * tb_eval['val_recall'])/(tb_eval['val_precision'] + tb_eval['val_recall'])"
      ],
      "metadata": {
        "id": "ZmW6B8G3b2sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lineplot(data = tb_eval, x = 'epoch', y = 'f1_score', label = \"Train\")\n",
        "sns.lineplot(data = tb_eval, x = 'epoch', y = 'val_f1_score', label = \"Test\")"
      ],
      "metadata": {
        "id": "kL3x6u7eki8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model_2.predict(X_test_trans)\n",
        "y_pred = [1 if x > 0.5 else 0 for x in y_pred_prob]\n",
        "print(f\"F1-Score no Conjunto de Teste: {np.round(f1_score(y_test, y_pred), 3)}\")"
      ],
      "metadata": {
        "id": "nLJ-TeNEk-v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilizando `TensorBoard`"
      ],
      "metadata": {
        "id": "OgaLa6OzmkSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = Sequential()\n",
        "\n",
        "model_3.add(Dense(80, input_dim=num_features, activation=\"relu\"))\n",
        "model_3.add(Dropout(0.1))\n",
        "model_3.add(Dense(80, activation=\"relu\"))\n",
        "model_3.add(Dropout(0.1))\n",
        "model_3.add(Dense(80, activation=\"relu\"))\n",
        "model_3.add(Dropout(0.1))\n",
        "model_3.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model_3.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer='adam', \n",
        "    metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard('./log', histogram_freq=1)"
      ],
      "metadata": {
        "id": "5do8SCNij5iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_3.fit(\n",
        "    X_train_trans.toarray(), y_train,\n",
        "    validation_split = 0.1, \n",
        "    epochs=25, \n",
        "    batch_size=64,\n",
        "    callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "id": "f3uE_DHzm3vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model_3.predict(X_test_trans)\n",
        "y_pred = [1 if x > 0.5 else 0 for x in y_pred_prob]\n",
        "print(f\"F1-Score no Conjunto de Teste: {np.round(f1_score(y_test, y_pred), 3)}\")"
      ],
      "metadata": {
        "id": "BAFiHyCLoLQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir log"
      ],
      "metadata": {
        "id": "y0Y9TGCrm_RS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bhVN5EBYnX2J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}